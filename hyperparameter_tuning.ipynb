{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latihan Regresi\n",
    "Pada latihan pertama kita akan menggunakan dataset fetch_california_housing dari Scikit-learn untuk melakukan regresi menggunakan Random Forest Regressor. Dataset California Housing adalah dataset yang berisi informasi harga rumah berdasarkan berbagai fitur, dan tujuan model ini adalah memprediksi harga rata-rata rumah di wilayah tertentu.\n",
    "\n",
    "Dalam studi kasus ini, kita akan melakukan hyperparameter tuning pada model Random Forest Regressor dan membandingkan performa serta efisiensi antara Grid Search, Random Search, dan Bayesian Optimization.\n",
    "\n",
    "Pertama-tama, mari kita muat dataset yang akan digunakan. Pada latihan ini, kita tidak akan membahas pre-processing terlalu dalam dengan anggapan Anda sudah menguasai materi tersebut pada modul-modul sebelumnya. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: (14448, 8)\n",
      "Shape of testing data: (6192, 8)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    " \n",
    "# Mengunduh dataset California Housing\n",
    "X, y = fetch_california_housing(return_X_y=True)\n",
    " \n",
    "# Membagi dataset menjadi training set dan testing set (70% training, 30% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    " \n",
    "# Melakukan scaling pada data (penting untuk regresi)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    " \n",
    "print(\"Shape of training data:\", X_train.shape)\n",
    "print(\"Shape of testing data:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dos-f13650d2069a10491933d86f18a94c1920241017155640.jpeg\n",
    "Output di atas memiliki 14.448 data latih dan 6192 data uji. Kemudian, mari kita latih model machine learning agar dapat memprediksi nilai kontinu karena kita akan membuat sebuah model regresi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial MSE on test set (without tuning): 0.26\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    " \n",
    "# Inisialisasi model Random Forest Regressor\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    " \n",
    "# Evaluasi awal model tanpa tuning\n",
    "y_pred = rf.predict(X_test)\n",
    "initial_mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Initial MSE on test set (without tuning): {initial_mse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dos-b0b4e213eff8aef87ad0c45b825011a020241017155640.jpeg\n",
    "Nilai MSE pada model regresi ini 0.26 tanpa melakukan hyperparameter tuning. Nilai ini sudah cukup bagus mengingat kita menggunakan salah satu algoritma ensemble yaitu RandomForestRegressor. Anda dapat melakukan eksplorasi menggunakan algoritma lainnya juga, ya.\n",
    "\n",
    "Selanjutnya, mari kita lakukan hyperparameter tuning dimulai dengan grid search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   9.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   9.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   9.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  19.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  10.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   8.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  12.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  24.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  25.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  11.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  19.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   9.0s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  11.0s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  28.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  29.0s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   9.0s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  23.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  11.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  32.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  29.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   9.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  24.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  19.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  19.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  32.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  16.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  23.8s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  35.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  17.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  29.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  15.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  43.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  15.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  16.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  34.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  30.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  35.8s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  15.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  21.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  26.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  16.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  33.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  14.8s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  40.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  16.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  13.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  28.0s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  35.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  13.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  37.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  21.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  33.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  36.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  22.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  41.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  17.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  14.4s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  31.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  19.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  35.4s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  15.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  38.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  19.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  17.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  31.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  31.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  15.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  38.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  17.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  25.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  39.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  36.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  44.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  22.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  36.0s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  55.9s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  35.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  58.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  27.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  25.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  27.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  55.0s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  48.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  22.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  24.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  57.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  16.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  55.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  46.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  27.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  52.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  26.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  40.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  39.8s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  37.1s\n",
      "Best parameters (Grid Search): {'bootstrap': True, 'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "MSE after Grid Search: 0.25\n",
      "Waktu eksekusi: 693.3365 detik\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "start_time = time.time()  # Mencatat waktu mulai\n",
    "\n",
    "# Definisikan parameter grid untuk Grid Search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Inisialisasi RandomForestRegressor\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Inisialisasi GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Output hasil terbaik\n",
    "print(f\"Best parameters (Grid Search): {grid_search.best_params_}\")\n",
    "best_rf_grid = grid_search.best_estimator_\n",
    "\n",
    "# Evaluasi performa model setelah Grid Search\n",
    "y_pred_grid = best_rf_grid.predict(X_test)\n",
    "grid_search_mse = mean_squared_error(y_test, y_pred_grid)\n",
    "print(f\"MSE after Grid Search: {grid_search_mse:.2f}\")\n",
    "end_time = time.time()  # Mencatat waktu selesai\n",
    "execution_time = end_time - start_time  # Menghitung selisih waktu\n",
    "print(f\"Waktu eksekusi: {execution_time:.4f} detik\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dos-37cdd6830c861e84b3a7f1065c46b37920241017155640.jpeg\n",
    "Nilai MSE setelah melalui grid search berkurang 0.02 menjadi 0.21, hal ini berarti hyperparameter pada foundation model belum mencapai titik optimalnya. Sebagai catatan, Anda juga dapat menambahkan lebih banyak kombinasi hyperparameter seperti berikut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "    'max_depth': [10, 20, 30, 40],\n",
    "    'min_samples_split': [2, 5, 10, 15],\n",
    "    'min_samples_leaf': [1, 2, 4, 8],\n",
    "    'bootstrap': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dos-ec6027e7a2e474be37b5ced90c0131ad20241017155641.jpeg\n",
    "Namun, perlu Anda ingat dengan menambahkan kombinasi hyperparameter akan meningkatkan jumlah kombinasi secara signifikan. Hal ini menyebabkan konsumsi memori akan meningkat jauh lebih besar bahkan dapat menyebabkan crash atau error ketika proses tuning dilakukan.\n",
    "\n",
    "dos-4a53b3030aad6eb2a6ba48d69c9915f320241017155640.jpeg\n",
    "\n",
    "Ini menjadi salah satu kelemahan grid search yang sudah kita bahas pada materi sebelumnya karena metode ini akan melatih seluruh kombinasi dari hyperparameter yang kita tentukan.\n",
    "\n",
    "Selanjutnya, mari kita lakukan optimasi dengan menggunakan random search menggunakan kode berikut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  24.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  32.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  36.0s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=6, n_estimators=300; total time=  48.9s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=8, n_estimators=400; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=8, n_estimators=400; total time= 1.8min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=8, n_estimators=400; total time= 1.4min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=6, n_estimators=300; total time=  44.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=4, n_estimators=300; total time=  35.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=4, n_estimators=300; total time=  29.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=6, n_estimators=300; total time=  49.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=4, n_estimators=300; total time=  33.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=6, n_estimators=400; total time=  46.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=6, n_estimators=400; total time=  43.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=6, n_estimators=400; total time=  43.8s\n",
      "Best parameters (Random Search): {'n_estimators': np.int64(300), 'min_samples_split': np.int64(6), 'min_samples_leaf': np.int64(2), 'max_depth': np.int64(30), 'bootstrap': True}\n",
      "MSE after Grid Search: 0.25\n",
      "Waktu eksekusi: 232.4868 detik\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    " \n",
    "start_time = time.time()  # Mencatat waktu mulai\n",
    "# Definisikan ruang pencarian untuk Random Search\n",
    "param_dist = {\n",
    "    'n_estimators': np.arange(100, 500, 100),\n",
    "    'max_depth': [None] + list(np.arange(10, 50, 10)),\n",
    "    'min_samples_split': np.arange(2, 11, 2),\n",
    "    'min_samples_leaf': np.arange(1, 5),\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    " \n",
    "# Inisialisasi RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, n_iter=5, cv=3, n_jobs=-1, verbose=2, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    " \n",
    "# Output hasil terbaik\n",
    "print(f\"Best parameters (Random Search): {random_search.best_params_}\")\n",
    "best_rf_random = random_search.best_estimator_\n",
    " \n",
    "# Evaluasi performa model setelah Random Search\n",
    "y_pred_random = best_rf_random.predict(X_test)\n",
    "random_search_mse = mean_squared_error(y_test, y_pred_random)\n",
    "print(f\"MSE after Grid Search: {random_search_mse:.2f}\")\n",
    "end_time = time.time()  # Mencatat waktu selesai\n",
    "execution_time = end_time - start_time  # Menghitung selisih waktu\n",
    "print(f\"Waktu eksekusi: {execution_time:.4f} detik\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dos-1c03d155f2f9aff9d30a2daffbf082f520241017155641.jpeg\n",
    "Pada output di atas nampak jelas sebuah perbedaan yang signifikan yaitu pada waktu eksekusi. Dengan menggunakan random search, komputer hanya mencari n kombinasi sesuai jumlah kombinasi yang ingin dicari. Semakin banyak nilai yang Anda tentukan, semakin lama juga waktu yang diperlukan, begitu juga sebaliknya.\n",
    "\n",
    "Last but not least, mari kita lakukan optimasi dengan menggunakan bayesian optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-optimize\n",
      "  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/yoga/.asdf/installs/python/anaconda3-2024.06-1/envs/main-ds/lib/python3.9/site-packages (from scikit-optimize) (1.4.2)\n",
      "Collecting pyaml>=16.9 (from scikit-optimize)\n",
      "  Downloading pyaml-24.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /home/yoga/.asdf/installs/python/anaconda3-2024.06-1/envs/main-ds/lib/python3.9/site-packages (from scikit-optimize) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/yoga/.asdf/installs/python/anaconda3-2024.06-1/envs/main-ds/lib/python3.9/site-packages (from scikit-optimize) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /home/yoga/.asdf/installs/python/anaconda3-2024.06-1/envs/main-ds/lib/python3.9/site-packages (from scikit-optimize) (1.5.2)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/yoga/.asdf/installs/python/anaconda3-2024.06-1/envs/main-ds/lib/python3.9/site-packages (from scikit-optimize) (24.1)\n",
      "Requirement already satisfied: PyYAML in /home/yoga/.asdf/installs/python/anaconda3-2024.06-1/envs/main-ds/lib/python3.9/site-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/yoga/.asdf/installs/python/anaconda3-2024.06-1/envs/main-ds/lib/python3.9/site-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.5.0)\n",
      "Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
      "Downloading pyaml-24.9.0-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: pyaml, scikit-optimize\n",
      "Successfully installed pyaml-24.9.0 scikit-optimize-0.10.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END bootstrap=True, max_depth=39, min_samples_leaf=4, min_samples_split=5, n_estimators=368; total time=  39.3s\n",
      "[CV] END bootstrap=True, max_depth=39, min_samples_leaf=4, min_samples_split=5, n_estimators=368; total time=  40.1s\n",
      "[CV] END bootstrap=True, max_depth=39, min_samples_leaf=4, min_samples_split=5, n_estimators=368; total time=  40.2s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END bootstrap=False, max_depth=45, min_samples_leaf=2, min_samples_split=10, n_estimators=446; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=45, min_samples_leaf=2, min_samples_split=10, n_estimators=446; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=45, min_samples_leaf=2, min_samples_split=10, n_estimators=446; total time= 1.3min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END bootstrap=True, max_depth=47, min_samples_leaf=1, min_samples_split=5, n_estimators=175; total time=  22.1s\n",
      "[CV] END bootstrap=True, max_depth=47, min_samples_leaf=1, min_samples_split=5, n_estimators=175; total time=  23.4s\n",
      "[CV] END bootstrap=True, max_depth=47, min_samples_leaf=1, min_samples_split=5, n_estimators=175; total time=  24.7s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END bootstrap=False, max_depth=17, min_samples_leaf=3, min_samples_split=8, n_estimators=309; total time=  54.1s\n",
      "[CV] END bootstrap=False, max_depth=17, min_samples_leaf=3, min_samples_split=8, n_estimators=309; total time=  54.6s\n",
      "[CV] END bootstrap=False, max_depth=17, min_samples_leaf=3, min_samples_split=8, n_estimators=309; total time=  56.3s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END bootstrap=False, max_depth=28, min_samples_leaf=3, min_samples_split=8, n_estimators=462; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=28, min_samples_leaf=3, min_samples_split=8, n_estimators=462; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=28, min_samples_leaf=3, min_samples_split=8, n_estimators=462; total time= 1.2min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END bootstrap=False, max_depth=48, min_samples_leaf=1, min_samples_split=4, n_estimators=420; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=48, min_samples_leaf=1, min_samples_split=4, n_estimators=420; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=48, min_samples_leaf=1, min_samples_split=4, n_estimators=420; total time= 1.2min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END bootstrap=False, max_depth=41, min_samples_leaf=2, min_samples_split=9, n_estimators=337; total time=  54.6s\n",
      "[CV] END bootstrap=False, max_depth=41, min_samples_leaf=2, min_samples_split=9, n_estimators=337; total time=  55.0s\n",
      "[CV] END bootstrap=False, max_depth=41, min_samples_leaf=2, min_samples_split=9, n_estimators=337; total time=  56.8s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoga/.asdf/installs/python/anaconda3-2024.06-1/envs/main-ds/lib/python3.9/site-packages/numpy/ma/core.py:2846: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, max_depth=47, min_samples_leaf=2, min_samples_split=9, n_estimators=230; total time=  32.0s\n",
      "[CV] END bootstrap=False, max_depth=47, min_samples_leaf=2, min_samples_split=9, n_estimators=230; total time=  32.3s\n",
      "[CV] END bootstrap=False, max_depth=47, min_samples_leaf=2, min_samples_split=9, n_estimators=230; total time=  33.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END bootstrap=False, max_depth=38, min_samples_leaf=4, min_samples_split=5, n_estimators=252; total time=  33.1s\n",
      "[CV] END bootstrap=False, max_depth=38, min_samples_leaf=4, min_samples_split=5, n_estimators=252; total time=  33.2s\n",
      "[CV] END bootstrap=False, max_depth=38, min_samples_leaf=4, min_samples_split=5, n_estimators=252; total time=  34.3s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END bootstrap=True, max_depth=43, min_samples_leaf=3, min_samples_split=4, n_estimators=331; total time=  33.7s\n",
      "[CV] END bootstrap=True, max_depth=43, min_samples_leaf=3, min_samples_split=4, n_estimators=331; total time=  33.8s\n",
      "[CV] END bootstrap=True, max_depth=43, min_samples_leaf=3, min_samples_split=4, n_estimators=331; total time=  35.3s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  38.0s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  38.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  39.1s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END bootstrap=True, max_depth=50, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  48.4s\n",
      "[CV] END bootstrap=True, max_depth=50, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  49.4s\n",
      "[CV] END bootstrap=True, max_depth=50, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  49.7s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END bootstrap=True, max_depth=50, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   9.1s\n",
      "[CV] END bootstrap=True, max_depth=50, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   9.4s\n",
      "[CV] END bootstrap=True, max_depth=50, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   9.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END bootstrap=True, max_depth=50, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  46.6s\n",
      "[CV] END bootstrap=True, max_depth=50, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  46.6s\n",
      "[CV] END bootstrap=True, max_depth=50, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  46.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   8.0s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   8.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   8.8s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END bootstrap=True, max_depth=50, min_samples_leaf=3, min_samples_split=6, n_estimators=500; total time=  48.1s\n",
      "[CV] END bootstrap=True, max_depth=50, min_samples_leaf=3, min_samples_split=6, n_estimators=500; total time=  48.5s\n",
      "[CV] END bootstrap=True, max_depth=50, min_samples_leaf=3, min_samples_split=6, n_estimators=500; total time=  49.3s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=396; total time=  31.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=396; total time=  31.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=396; total time=  32.4s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END bootstrap=True, max_depth=11, min_samples_leaf=4, min_samples_split=2, n_estimators=113; total time=   9.3s\n",
      "[CV] END bootstrap=True, max_depth=11, min_samples_leaf=4, min_samples_split=2, n_estimators=113; total time=  10.2s\n",
      "[CV] END bootstrap=True, max_depth=11, min_samples_leaf=4, min_samples_split=2, n_estimators=113; total time=  10.7s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END bootstrap=True, max_depth=50, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=  10.6s\n",
      "[CV] END bootstrap=True, max_depth=50, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=  10.7s\n",
      "[CV] END bootstrap=True, max_depth=50, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=  10.8s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END bootstrap=True, max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END bootstrap=True, max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=  58.9s\n",
      "[CV] END bootstrap=True, max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=  59.5s\n",
      "[CV] END bootstrap=True, max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time= 1.0min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END bootstrap=True, max_depth=33, min_samples_leaf=1, min_samples_split=10, n_estimators=459; total time=  48.9s\n",
      "[CV] END bootstrap=True, max_depth=33, min_samples_leaf=1, min_samples_split=10, n_estimators=459; total time=  49.2s\n",
      "[CV] END bootstrap=True, max_depth=33, min_samples_leaf=1, min_samples_split=10, n_estimators=459; total time=  51.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END bootstrap=True, max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  50.7s\n",
      "[CV] END bootstrap=True, max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  51.0s\n",
      "[CV] END bootstrap=True, max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  51.1s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END bootstrap=True, max_depth=29, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  48.2s\n",
      "[CV] END bootstrap=True, max_depth=29, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  48.3s\n",
      "[CV] END bootstrap=True, max_depth=29, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  48.8s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END bootstrap=True, max_depth=36, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=36, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=36, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time= 1.0min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END bootstrap=True, max_depth=27, min_samples_leaf=4, min_samples_split=10, n_estimators=118; total time=  11.1s\n",
      "[CV] END bootstrap=True, max_depth=27, min_samples_leaf=4, min_samples_split=10, n_estimators=118; total time=  11.5s\n",
      "[CV] END bootstrap=True, max_depth=27, min_samples_leaf=4, min_samples_split=10, n_estimators=118; total time=  12.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END bootstrap=True, max_depth=26, min_samples_leaf=4, min_samples_split=2, n_estimators=495; total time=  56.1s\n",
      "[CV] END bootstrap=True, max_depth=26, min_samples_leaf=4, min_samples_split=2, n_estimators=495; total time=  56.8s\n",
      "[CV] END bootstrap=True, max_depth=26, min_samples_leaf=4, min_samples_split=2, n_estimators=495; total time= 1.0min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END bootstrap=True, max_depth=34, min_samples_leaf=2, min_samples_split=4, n_estimators=500; total time=  55.5s\n",
      "[CV] END bootstrap=True, max_depth=34, min_samples_leaf=2, min_samples_split=4, n_estimators=500; total time=  56.0s\n",
      "[CV] END bootstrap=True, max_depth=34, min_samples_leaf=2, min_samples_split=4, n_estimators=500; total time=  57.1s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END bootstrap=True, max_depth=35, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  54.9s\n",
      "[CV] END bootstrap=True, max_depth=35, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  56.4s\n",
      "[CV] END bootstrap=True, max_depth=35, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  56.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END bootstrap=True, max_depth=23, min_samples_leaf=1, min_samples_split=2, n_estimators=101; total time=  13.2s\n",
      "[CV] END bootstrap=True, max_depth=23, min_samples_leaf=1, min_samples_split=2, n_estimators=101; total time=  14.8s\n",
      "[CV] END bootstrap=True, max_depth=23, min_samples_leaf=1, min_samples_split=2, n_estimators=101; total time=  15.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END bootstrap=True, max_depth=32, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  12.7s\n",
      "[CV] END bootstrap=True, max_depth=32, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  13.1s\n",
      "[CV] END bootstrap=True, max_depth=32, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  13.1s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END bootstrap=True, max_depth=21, min_samples_leaf=1, min_samples_split=8, n_estimators=491; total time=  51.5s\n",
      "[CV] END bootstrap=True, max_depth=21, min_samples_leaf=1, min_samples_split=8, n_estimators=491; total time=  54.4s\n",
      "[CV] END bootstrap=True, max_depth=21, min_samples_leaf=1, min_samples_split=8, n_estimators=491; total time=  54.8s\n",
      "Best parameters (Bayesian Optimization): OrderedDict([('bootstrap', True), ('max_depth', 36), ('min_samples_leaf', 1), ('min_samples_split', 2), ('n_estimators', 500)])\n",
      "MSE after Grid Search: 0.25\n",
      "Waktu eksekusi: 1491.1036 detik\n"
     ]
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    " \n",
    "start_time = time.time()  # Mencatat waktu mulai\n",
    " \n",
    "# Definisikan ruang pencarian untuk Bayesian Optimization\n",
    "param_space = {\n",
    "    'n_estimators': (100, 500),\n",
    "    'max_depth': (10, 50),\n",
    "    'min_samples_split': (2, 10),\n",
    "    'min_samples_leaf': (1, 4),\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    " \n",
    "# Inisialisasi BayesSearchCV\n",
    "bayes_search = BayesSearchCV(estimator=rf, search_spaces=param_space, n_iter=32, cv=3, n_jobs=-1, verbose=2, random_state=42)\n",
    "bayes_search.fit(X_train, y_train)\n",
    " \n",
    "# Output hasil terbaik\n",
    "print(f\"Best parameters (Bayesian Optimization): {bayes_search.best_params_}\")\n",
    "best_rf_bayes = bayes_search.best_estimator_\n",
    " \n",
    "# Evaluasi performa model setelah Random Search\n",
    "y_pred_bayes = best_rf_bayes.predict(X_test)\n",
    "bayes_mse = mean_squared_error(y_test, y_pred_bayes)\n",
    "print(f\"MSE after Grid Search: {bayes_mse:.2f}\")\n",
    "end_time = time.time()  # Mencatat waktu selesai\n",
    "execution_time = end_time - start_time  # Menghitung selisih waktu\n",
    "print(f\"Waktu eksekusi: {execution_time:.4f} detik\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dos-0630458a1f18ef57cb5d5b3f6f65765320241017155641.jpeg\n",
    "Berbeda dengan grid search dan random search, output yang diberikan oleh bayesian optimization hanya memiliki satu kandidat kombinasi yang berulang kali dihitung. Perulangan ini akan terus dilakukan hingga performa model machine learning sudah tidak ada perubahan.\n",
    "\n",
    "Kesimpulan dari ketiga metode ini dapat kita rangkum seperti berikut.\n",
    "\n",
    "Grid Search memberikan hasil optimal tetapi membutuhkan waktu komputasi yang lebih lama karena mencoba semua kombinasi hyperparameter yang ada.\n",
    "Random Search memberikan hasil yang baik dengan waktu komputasi yang lebih cepat, tetapi bisa saja kehilangan kombinasi hyperparameter yang optimal.\n",
    "Bayesian Optimization memberikan keseimbangan terbaik antara efisiensi komputasi dan hasil optimal, memanfaatkan informasi dari iterasi sebelumnya untuk mencari kombinasi hyperparameter terbaik.\n",
    "Dengan dataset California Housing, kita dapat melihat perbedaan performa model secara lebih signifikan setelah dilakukan hyperparameter tuning. Bayesian Optimization adalah pilihan yang baik jika Anda ingin mengoptimalkan model secara lebih efisien, sementara Grid Search memberikan hasil yang lebih pasti dengan menguji semua kombinasi.\n",
    "\n",
    "Ada sebuah fun fact ketika Anda mencoba mengimplementasikan hyperparameter tuning terhadap sebuah model machine learning. Kelak ketika Anda mencoba melakukan tuning jangan heran jika performa model tidak berubah sama sekali atau bahkan menurun. \n",
    "\n",
    "Penurunan akurasi setelah hyperparameter tuning adalah hal yang umum terjadi dalam pembangunan model machine learning. Agar Anda memahami perbedaan tersebut, mari kita coba gunakan latihan klasifikasi sebagai playground untuk eksplorasi segala kemungkinan yang bisa terjadi ketika melakukan hyperparameter tuning.\n",
    "\n",
    "\n",
    "\n",
    "Latihan Klasifikasi\n",
    "Pada latihan kedua ini, Anda akan membangun sebuah model klasifikasi dengan dataset yang berisi informasi tentang klasifikasi kredit. Dataset ini memiliki sekitar 1.000 baris dan sejumlah fitur yang menjelaskan profil pelanggan, seperti riwayat kredit, status pekerjaan, pendapatan, dan sebagainya. Seperti biasa, mari kita lakukan loading dataset dan sedikit preprocessing agar data dapat dilatih dengan baik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: (700, 48)\n",
      "Shape of testing data: (300, 48)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    " \n",
    "# Mengunduh dataset German Credit dari OpenML\n",
    "X, y = fetch_openml(name='credit-g', version=1, return_X_y=True, as_frame=True)\n",
    " \n",
    "# Konversi target menjadi numerik\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)  # Mengubah 'good' menjadi 1 dan 'bad' menjadi 0\n",
    " \n",
    "# Melakukan One-Hot Encoding pada fitur kategorikal\n",
    "X_encoded = pd.get_dummies(X, drop_first=True)  # Konversi fitur kategorikal menjadi numerik\n",
    " \n",
    "# Membagi dataset menjadi training set dan testing set (70% training, 30% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3, random_state=42)\n",
    " \n",
    "print(\"Shape of training data:\", X_train.shape)\n",
    "print(\"Shape of testing data:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dos-a93cc2c14645f4567166ac0c951d96a820241017155640.jpeg\n",
    "Mari kita asumsikan sampai pada titik ini dataset yang digunakan sudah siap dilatih sehingga Anda hanya perlu membangun sebuah foundation model dengan menggunakan kode berikut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy on test set (without tuning): 0.76\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    " \n",
    "# Inisialisasi model Random Forest tanpa hyperparameter tuning\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    " \n",
    "# Evaluasi awal model tanpa tuning\n",
    "initial_score = rf.score(X_test, y_test)\n",
    "print(f\"Initial accuracy on test set (without tuning): {initial_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dos-f4b0054c8343297f7578b923dcf379c520241017155640.jpeg\n",
    "Sama halnya dengan latihan pada kasus regresi tahap berikutnya Anda hanya perlu membangun sebuah model dengan menggunakan hyperparameter tuning dimulai dari grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=2, n_estimators=300; total time=   1.3s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=2, n_estimators=300; total time=   1.3s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=2, n_estimators=300; total time=   1.5s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=5, n_estimators=300; total time=   1.4s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=5, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=5, n_estimators=300; total time=   1.3s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=10, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=10, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=10, n_estimators=300; total time=   1.3s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=2, n_estimators=300; total time=   1.6s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=2, n_estimators=300; total time=   1.4s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=2, n_estimators=300; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=5, n_estimators=300; total time=   1.5s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=5, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.8s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=5, n_estimators=300; total time=   2.3s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=10, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=10, n_estimators=300; total time=   1.5s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=10, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_split=2, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_split=2, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_split=2, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_split=5, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_split=5, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_split=5, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_split=10, n_estimators=300; total time=   1.3s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_split=10, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_split=10, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=2, n_estimators=300; total time=   1.4s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=2, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=2, n_estimators=300; total time=   1.3s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=5, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=5, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=5, n_estimators=300; total time=   1.3s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=10, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=10, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=10, n_estimators=300; total time=   1.3s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=2, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=2, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=2, n_estimators=300; total time=   1.3s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=2, n_estimators=300; total time=   1.3s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=2, n_estimators=300; total time=   1.3s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=5, n_estimators=300; total time=   1.3s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=5, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=5, n_estimators=300; total time=   1.5s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=10, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=10, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=10, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_split=2, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_split=2, n_estimators=300; total time=   1.4s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_split=2, n_estimators=300; total time=   1.6s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_split=5, n_estimators=300; total time=   1.3s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_split=10, n_estimators=100; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_split=5, n_estimators=300; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_split=5, n_estimators=300; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_split=10, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_split=10, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_split=10, n_estimators=300; total time=   1.0s\n",
      "Best parameters (Grid Search): {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Accuracy after Grid Search: 0.76\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    " \n",
    "# Definisikan parameter grid untuk Grid Search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    " \n",
    "# Inisialisasi GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    " \n",
    "# Output hasil terbaik\n",
    "print(f\"Best parameters (Grid Search): {grid_search.best_params_}\")\n",
    "best_rf_grid = grid_search.best_estimator_\n",
    " \n",
    "# Evaluasi performa model pada test set\n",
    "grid_search_score = best_rf_grid.score(X_test, y_test)\n",
    "print(f\"Accuracy after Grid Search: {grid_search_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dos-17198a5a3b6423abeee98b37435ba2b520241017155640.jpeg\n",
    "\n",
    "Langkah berikutnya, lakukan hal yang sama dengan sebelumnya, tetapi menggunakan random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_split=10, n_estimators=400; total time=   1.5s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_split=10, n_estimators=400; total time=   1.5s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_split=10, n_estimators=400; total time=   1.7s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=2, n_estimators=400; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=2, n_estimators=400; total time=   2.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=2, n_estimators=400; total time=   2.2s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_split=10, n_estimators=400; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_split=10, n_estimators=400; total time=   2.4s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=2, n_estimators=400; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_split=10, n_estimators=400; total time=   2.4s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=2, n_estimators=400; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=2, n_estimators=400; total time=   2.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_split=2, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_split=2, n_estimators=500; total time=   2.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_split=2, n_estimators=500; total time=   2.1s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_split=2, n_estimators=500; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_split=5, n_estimators=400; total time=   1.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=5, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_split=5, n_estimators=400; total time=   1.5s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_split=5, n_estimators=400; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_split=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_split=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=5, n_estimators=300; total time=   1.7s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=5, n_estimators=300; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=10, n_estimators=300; total time=   1.5s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=10, n_estimators=300; total time=   1.5s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=10, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=5, n_estimators=500; total time=   2.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=5, n_estimators=500; total time=   2.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=5, n_estimators=500; total time=   2.2s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=2, n_estimators=500; total time=   2.6s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=2, n_estimators=500; total time=   2.3s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_split=2, n_estimators=500; total time=   2.8s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=10, n_estimators=500; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=10, n_estimators=500; total time=   2.3s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_split=10, n_estimators=500; total time=   2.5s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_split=5, n_estimators=500; total time=   2.6s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_split=5, n_estimators=500; total time=   2.8s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_split=10, n_estimators=300; total time=   1.5s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_split=10, n_estimators=300; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_split=5, n_estimators=500; total time=   3.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_split=10, n_estimators=300; total time=   1.0s\n",
      "Best parameters (Random Search): {'n_estimators': np.int64(200), 'min_samples_split': 5, 'max_depth': np.int64(30), 'criterion': 'gini'}\n",
      "Accuracy after Random Search: 0.76\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    " \n",
    "# Definisikan ruang pencarian untuk Random Search\n",
    "param_dist = {\n",
    "    'n_estimators': np.linspace(100, 500, 5, dtype=int),\n",
    "    'max_depth': np.linspace(10, 50, 5, dtype=int),\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    " \n",
    "# Inisialisasi RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, n_iter=20, cv=3, n_jobs=-1, verbose=2, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    " \n",
    "# Output hasil terbaik\n",
    "print(f\"Best parameters (Random Search): {random_search.best_params_}\")\n",
    "best_rf_random = random_search.best_estimator_\n",
    " \n",
    "# Evaluasi performa model pada test set\n",
    "random_search_score = best_rf_random.score(X_test, y_test)\n",
    "print(f\"Accuracy after Random Search: {random_search_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dos-3821bbee2757f80d68d5f965c02808f120241017155640.jpeg\n",
    "Whoops, jika Anda perhatikan, kedua metode di atas memiliki performa yang sama dengan foundation model yang sudah kita bangun di awal latihan. Sebagai pembuktian, mari kita gunakan bayesian optimization untuk melakukan hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END criterion=gini, max_depth=39, min_samples_split=9, n_estimators=226; total time=   0.7s\n",
      "[CV] END criterion=gini, max_depth=39, min_samples_split=9, n_estimators=226; total time=   1.3s\n",
      "[CV] END criterion=gini, max_depth=39, min_samples_split=9, n_estimators=226; total time=   1.3s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END criterion=entropy, max_depth=45, min_samples_split=4, n_estimators=480; total time=   1.7s\n",
      "[CV] END criterion=entropy, max_depth=45, min_samples_split=4, n_estimators=480; total time=   2.1s\n",
      "[CV] END criterion=entropy, max_depth=45, min_samples_split=4, n_estimators=480; total time=   2.8s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END criterion=gini, max_depth=47, min_samples_split=3, n_estimators=273; total time=   1.2s\n",
      "[CV] END criterion=gini, max_depth=47, min_samples_split=3, n_estimators=273; total time=   1.1s\n",
      "[CV] END criterion=gini, max_depth=47, min_samples_split=3, n_estimators=273; total time=   1.4s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END criterion=entropy, max_depth=17, min_samples_split=7, n_estimators=421; total time=   1.3s\n",
      "[CV] END criterion=entropy, max_depth=17, min_samples_split=7, n_estimators=421; total time=   1.4s\n",
      "[CV] END criterion=entropy, max_depth=17, min_samples_split=7, n_estimators=421; total time=   1.7s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END criterion=entropy, max_depth=28, min_samples_split=6, n_estimators=386; total time=   1.2s\n",
      "[CV] END criterion=entropy, max_depth=28, min_samples_split=6, n_estimators=386; total time=   1.7s\n",
      "[CV] END criterion=entropy, max_depth=28, min_samples_split=6, n_estimators=386; total time=   1.9s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END criterion=entropy, max_depth=48, min_samples_split=3, n_estimators=175; total time=   0.6s\n",
      "[CV] END criterion=entropy, max_depth=48, min_samples_split=3, n_estimators=175; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=48, min_samples_split=3, n_estimators=175; total time=   0.8s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END criterion=entropy, max_depth=41, min_samples_split=5, n_estimators=450; total time=   1.5s\n",
      "[CV] END criterion=entropy, max_depth=41, min_samples_split=5, n_estimators=450; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=41, min_samples_split=5, n_estimators=450; total time=   1.9s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END criterion=entropy, max_depth=47, min_samples_split=6, n_estimators=435; total time=   1.4s\n",
      "[CV] END criterion=entropy, max_depth=47, min_samples_split=6, n_estimators=435; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=47, min_samples_split=6, n_estimators=435; total time=   2.1s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END criterion=entropy, max_depth=38, min_samples_split=9, n_estimators=266; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=38, min_samples_split=9, n_estimators=266; total time=   1.1s\n",
      "[CV] END criterion=entropy, max_depth=38, min_samples_split=9, n_estimators=266; total time=   0.9s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END criterion=gini, max_depth=43, min_samples_split=8, n_estimators=202; total time=   0.6s\n",
      "[CV] END criterion=gini, max_depth=43, min_samples_split=8, n_estimators=202; total time=   0.8s\n",
      "[CV] END criterion=gini, max_depth=43, min_samples_split=8, n_estimators=202; total time=   0.8s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END criterion=entropy, max_depth=47, min_samples_split=2, n_estimators=210; total time=   0.7s\n",
      "[CV] END criterion=entropy, max_depth=47, min_samples_split=2, n_estimators=210; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=47, min_samples_split=2, n_estimators=210; total time=   0.8s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END criterion=gini, max_depth=48, min_samples_split=10, n_estimators=474; total time=   1.7s\n",
      "[CV] END criterion=gini, max_depth=48, min_samples_split=10, n_estimators=474; total time=   1.7s\n",
      "[CV] END criterion=gini, max_depth=48, min_samples_split=10, n_estimators=474; total time=   1.7s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END criterion=entropy, max_depth=49, min_samples_split=2, n_estimators=126; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=49, min_samples_split=2, n_estimators=126; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=49, min_samples_split=2, n_estimators=126; total time=   0.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_split=5, n_estimators=454; total time=   1.7s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_split=5, n_estimators=454; total time=   2.4s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_split=5, n_estimators=454; total time=   2.4s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END criterion=entropy, max_depth=46, min_samples_split=10, n_estimators=499; total time=   1.6s\n",
      "[CV] END criterion=entropy, max_depth=46, min_samples_split=10, n_estimators=499; total time=   2.6s\n",
      "[CV] END criterion=entropy, max_depth=46, min_samples_split=10, n_estimators=499; total time=   2.8s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END criterion=gini, max_depth=16, min_samples_split=3, n_estimators=107; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=16, min_samples_split=3, n_estimators=107; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=16, min_samples_split=3, n_estimators=107; total time=   0.4s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END criterion=entropy, max_depth=18, min_samples_split=8, n_estimators=442; total time=   1.7s\n",
      "[CV] END criterion=entropy, max_depth=18, min_samples_split=8, n_estimators=442; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=18, min_samples_split=8, n_estimators=442; total time=   2.2s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END criterion=entropy, max_depth=37, min_samples_split=9, n_estimators=258; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=37, min_samples_split=9, n_estimators=258; total time=   1.2s\n",
      "[CV] END criterion=entropy, max_depth=37, min_samples_split=9, n_estimators=258; total time=   1.3s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=5, n_estimators=369; total time=   1.3s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=5, n_estimators=369; total time=   1.4s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=5, n_estimators=369; total time=   1.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=9, n_estimators=145; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=9, n_estimators=145; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=9, n_estimators=145; total time=   0.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=3, n_estimators=114; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=3, n_estimators=114; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=3, n_estimators=114; total time=   0.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END criterion=entropy, max_depth=25, min_samples_split=5, n_estimators=412; total time=   1.6s\n",
      "[CV] END criterion=entropy, max_depth=25, min_samples_split=5, n_estimators=412; total time=   1.5s\n",
      "[CV] END criterion=entropy, max_depth=25, min_samples_split=5, n_estimators=412; total time=   1.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_split=5, n_estimators=419; total time=   1.5s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_split=5, n_estimators=419; total time=   1.6s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_split=5, n_estimators=419; total time=   1.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_split=10, n_estimators=444; total time=   1.4s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_split=10, n_estimators=444; total time=   1.6s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_split=10, n_estimators=444; total time=   1.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_split=6, n_estimators=107; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_split=6, n_estimators=107; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_split=6, n_estimators=107; total time=   0.4s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=4, n_estimators=153; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=4, n_estimators=153; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=4, n_estimators=153; total time=   0.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END criterion=gini, max_depth=12, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=12, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=12, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END criterion=gini, max_depth=11, min_samples_split=5, n_estimators=500; total time=   1.7s\n",
      "[CV] END criterion=gini, max_depth=11, min_samples_split=5, n_estimators=500; total time=   1.6s\n",
      "[CV] END criterion=gini, max_depth=11, min_samples_split=5, n_estimators=500; total time=   1.7s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_split=4, n_estimators=395; total time=   1.3s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_split=4, n_estimators=395; total time=   1.2s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_split=4, n_estimators=395; total time=   1.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_split=5, n_estimators=123; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_split=5, n_estimators=123; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_split=5, n_estimators=123; total time=   0.4s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END criterion=entropy, max_depth=14, min_samples_split=2, n_estimators=500; total time=   1.7s\n",
      "[CV] END criterion=entropy, max_depth=14, min_samples_split=2, n_estimators=500; total time=   1.7s\n",
      "[CV] END criterion=entropy, max_depth=14, min_samples_split=2, n_estimators=500; total time=   2.1s\n",
      "Best parameters (Bayesian Optimization): OrderedDict([('criterion', 'entropy'), ('max_depth', 10), ('min_samples_split', 5), ('n_estimators', 369)])\n",
      "Accuracy after Bayesian Optimization: 0.75\n"
     ]
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    " \n",
    "# Definisikan ruang pencarian untuk Bayesian Optimization\n",
    "param_space = {\n",
    "    'n_estimators': (100, 500),\n",
    "    'max_depth': (10, 50),\n",
    "    'min_samples_split': (2, 10),\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    " \n",
    "# Inisialisasi BayesSearchCV\n",
    "bayes_search = BayesSearchCV(estimator=rf, search_spaces=param_space, n_iter=32, cv=3, n_jobs=-1, verbose=2, random_state=42)\n",
    "bayes_search.fit(X_train, y_train)\n",
    " \n",
    "# Output hasil terbaik\n",
    "print(f\"Best parameters (Bayesian Optimization): {bayes_search.best_params_}\")\n",
    "best_rf_bayes = bayes_search.best_estimator_\n",
    " \n",
    "# Evaluasi performa model pada test set\n",
    "bayes_search_score = best_rf_bayes.score(X_test, y_test)\n",
    "print(f\"Accuracy after Bayesian Optimization: {bayes_search_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dos-dccf039df33467720598eedb8940428220241017155641.jpeg\n",
    "Voilaa, ternyata dengan menggunakan metode apa pun, hasil yang diberikan cenderung sama saja dan bahkan terdapat performa yang menurun. Hal ini merupakan fun fact yang telah kita bahas sebelumnya. Pertanyaannya, mengapa hal ini bisa terjadi? \n",
    "\n",
    "Seperti yang sudah kita bahas penurunan akurasi setelah hyperparameter tuning adalah hal yang umum terjadi dalam pembangunan model machine learning, dan beberapa faktor yang berkontribusi terhadap masalah ini antara lain seperti berikut.\n",
    "\n",
    "Overfitting: tuning hyperparameter secara berlebihan bisa menyebabkan model terlalu sesuai dengan data pelatihan (overfit). Hal ini dapat menyebabkan performa model yang baik pada data pelatihan tetapi buruk pada data pengujian.\n",
    "Underfitting: sebaliknya, jika model tidak cukup kompleks setelah tuning, model bisa gagal menangkap pola penting dari data (underfit).\n",
    "Pemilihan Ruang Pencarian yang Tidak Tepat: jika rentang atau ruang hyperparameter yang dicari terlalu kecil atau tidak mencakup area yang optimal, hasil tuning dapat merugikan performa model.\n",
    "Evaluasi yang Tidak Konsisten: cross-validation yang kurang efektif atau ruang pencarian hyperparameter yang terlalu besar juga dapat membuat tuning kurang efektif.\n",
    "Dari berbagai macam penjelasan di atas, salah satu alasan model yang kita bangun tidak berubah karena dataset yang digunakan terlalu kecil atau dummy. Hal ini sengaja kami lakukan agar Anda dapat memahami perbedaan dari kedua latihan yang telah dilakukan. \n",
    "\n",
    "Untuk melakukan tuning yang lebih baik, Anda dapat menerapkan beberapa saran berikut.\n",
    "\n",
    "Memastikan bahwa dataset yang digunakan sudah baik.\n",
    "Memperluas ruang pencarian hyperparameter.\n",
    "Memfokuskan tuning pada hyperparameter kunci yang paling berdampak pada performa model, seperti n_estimators, max_depth, dan min_samples_split.\n",
    "Menggunakan cross-validation dengan lebih banyak fold untuk membuat evaluasi performa lebih stabil.\n",
    "Memperhatikan keseimbangan antara eksplorasi dan eksploitasi hyperparameter dengan menggunakan metode seperti Bayesian Optimization yang lebih efisien dalam memprediksi kombinasi optimal.\n",
    "Sebagai bentuk eksplorasi, Anda dapat melihat beberapa contoh penerapan hyperparameter tuning pada notebook berikut: Update MLP - Modul 8 Optimasi dengan Hyperparameter Tuning. Selain itu, Anda juga dapat menerapkan metode ini pada studi kasus lainnya ya. Psst, jangan lupa juga untuk menerapkan hyperparameter tuning pada submission akhir, ya!\n",
    "\n",
    "Sungguh tidak terasa sekarang Anda sudah mencapai akhir dari pembelajaran yang ada di kelas ini. Lika-liku pembangunan model machine learning telah Anda lewati dimulai dari pembangunan model, ragam model machine learning hingga bersahabat dengan error yang terjadi. Semua itu Anda lalui dengan gagah dan berani hingga akhirnya dapat membangun beragam model machine learning yang andal.\n",
    "\n",
    "Selamat, Anda telah menyelesaikan kelas Machine Learning untuk Pemula, You did something big! Jika Anda masih ingin bermain-main di kelas ini, silakan baca-baca kembali modul yang sudah ada, ya. Oiya, kami juga sangat menanti cerita sukses Anda dalam perjalanan sebagai seorang machine learning engineer yang andal. Jangan lupa untuk membagikan cerita sukses Anda kelak, ya. Sampai jumpa lagi champs!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main-ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
